package tagfixer

import "core:encoding/json"
import "core:fmt"
import "core:os"
import "core:strings"
import "core:text/regex"

/// Reads an exercise test file, its canonical data or tests toml file (metadata
/// in the text below) and adds description tag to each test if not already present.
/// The updated file doesn't overwrite the test file but it written to the provided
/// output path.
///
/// If one of the test description converted to snake case matches one of the
/// description in the metadata, then that description is associated with the
/// test. If none match, a bst guess english description is deriver from the
/// test name by reversing the snake case conversion.
/// If a description exists for a test, it is never overwritten.
main :: proc() {

	// This program will run once and exit so
	// there is no need to release memory manually, let the OS do it.

	// We can get the test metadata (description, uuid, reimplements)
	// from either its canonical data or the `.meta/tests.toml` file.

	// For canonical data, Odin returns the JSON blob as a tree of
	// `json.Value` and we cast it to the correct type based on the schema.
	// If the canonical data file doesn't follow the schema we
	// will get a casting error and that's okay.

	if len(os.args) != 4 {
		fmt.eprintln("Usage: tagfixer <testfile_path> <meta_data_path> <updated_testfile_path>")
		os.exit(1)
	}

	test_path := os.args[1]
	metadata_path := os.args[2]
	output_path := os.args[3]

	test_src, test_ok := os.read_entire_file_from_filename(test_path)
	if !test_ok {
		fmt.eprintf("Unable to open test file %s\n", test_path)
		os.exit(1)
	}

	// We can read the tests metadata from the `canonical-data.json`` or the `tests.toml`` file.
	// We don't need both methods for now but, since we have the code, let's allow both methods
	// in case there are additional informations needed later.
	read_metadata: proc(path: string) -> (Snake_English_Map, bool, Error)
	switch {
	case strings.ends_with(metadata_path, ".json"):
		read_metadata = read_canonical_data
	case strings.ends_with(metadata_path, ".toml"):
		read_metadata = read_toml_data
	case:
		fmt.eprintf("Expected metadata to be a .json or a .toml file but got%s\n", metadata_path)
		os.exit(1)
	}
	snk_to_eng, must_cap, err := read_metadata(metadata_path)
	switch err in err {
	case string:
		fmt.eprintln(err)
		os.exit(1)
	}

	// Add the descriptions to the test and write the updated file to the provided path.
	outfile, out_err := os.open(output_path, os.O_RDWR | os.O_CREATE | os.O_TRUNC, 0o644)
	if out_err != nil {
		fmt.eprintf("Unable to open output file %s\n", output_path)
		os.exit(1)
	}
	report := add_descriptions_to_tests(string(test_src), snk_to_eng, must_cap, outfile)

	// Report which tests were either found in the test file (unchanged)
	// or generated by rebuilding the english description from the snake case version.
	// This second points to either a mismatch between the snake case name in the file
	// and the description or a custom test for the track.
	need_header := true
	for entry in report {
		if entry.source == .Metadata { continue }
		if need_header {
			fmt.printf("\nWarnings:\n")
			fmt.printf("=========\n\n")
			need_header = false
		}
		fmt.printf("- test_%s:\n", entry.proc_name)
		source := "Already in file" if entry.source == .Original else "Rebuilt from proc. name"
		fmt.printf("  => %s:'%s'\n\n", source, entry.eng_name)
	}
}

// Allows errors to be nil (aka no error).
Error :: union {
	string,
}

// The snake case to english dictionary for an exercise.
Snake_English_Map :: map[string]string

// Whe are using a state machine to scan the test file.
Scan_State :: enum {
	Ouside,
	Found_Test_Attribute,
	Found_Description,
	Found_Task,
	Found_Test_Signature,
}

// Where does the description come from.
Source :: enum {
	Metadata,
	Rebuilt,
	Original,
}

Report :: struct {
	proc_name: string,
	eng_name:  string,
	source:    Source,
}

// Returns a list of test names that we found with a report on how they were generated.
add_descriptions_to_tests :: proc(
	test_src: string,
	snk_to_eng: Snake_English_Map,
	must_cap: bool,
	out: os.Handle,
) -> []Report {

	Test_Header :: struct {
		proc_name:     string,
		desc_line:     string,
		task_line:     string,
		sign_line:     string,
		comment_lines: [dynamic]string,
	}

	report: [dynamic]Report
	state: Scan_State
	hd := Test_Header{}
	// I found a couple of tests that didn't start with 'test_', accounting for that.
	proc_re, re_err := regex.create(`(test_)?([a-zA-Z0-9_]+)\s*::\s*proc`)
	ensure(re_err == nil)
	capture := regex.preallocate_capture()

	for line in strings.split(string(test_src), "\n") {
		switch state {
		case .Ouside:
			if strings.starts_with(line, "@(test)") {
				state = .Found_Test_Attribute
				hd = Test_Header{}
			} else {
				fmt.fprintln(out, line)
			}
		case .Found_Test_Attribute:
			// There could already be a description populated.
			// We are assuming there would not be a task without a description.
			if strings.starts_with(line, "/// description = ") {
				state = .Found_Description
				hd.desc_line = line
			} else if ng, ok := regex.match(proc_re, line, &capture); ok {
				state = .Found_Test_Signature
				hd.sign_line = line
				hd.proc_name = capture.groups[ng - 1]
			} else {
				// There may be comment lines, keep them
				// we will move them before @(test)
				append(&hd.comment_lines, line)
			}
		case .Found_Description:
			if strings.starts_with(line, "/// task_id = ") {
				state = .Found_Task
				hd.task_line = line
			} else if ng, ok := regex.match(proc_re, line, &capture); ok {
				state = .Found_Test_Signature
				hd.sign_line = line
				hd.proc_name = capture.groups[ng - 1]
			} else {
				// There may be comment lines, keep them
				// we will move them before @(test)
				append(&hd.comment_lines, line)
			}
		case .Found_Task:
			if ng, ok := regex.match(proc_re, line, &capture); ok {
				state = .Found_Test_Signature
				hd.sign_line = line
				hd.proc_name = capture.groups[ng - 1]
			} else {
				// There may be comment lines, keep them
				// we will move them before @(test)
				append(&hd.comment_lines, line)
			}
		case .Found_Test_Signature:
			// We are writing out
			//   comment lines (if any)
			//   @(test)
			//   /// description = ...
			//   // task_id = ... (only if we found a task line)
			//   // procedure signature line
			for comment in hd.comment_lines {
				fmt.fprintln(out, comment)
			}
			fmt.fprintln(out, "@(test)")
			if len(hd.desc_line) > 0 {
				desc_eng := rm_prefix(hd.desc_line, "/// description = ")
				append(
					&report,
					Report{proc_name = hd.proc_name, eng_name = desc_eng, source = .Original},
				)
				fmt.fprintln(out, hd.desc_line)
			} else {
				desc_eng, ok := snk_to_eng[hd.proc_name]
				if !ok {
					desc_eng = rebuild_english(hd.proc_name, must_cap)
					append(
						&report,
						Report{proc_name = hd.proc_name, eng_name = desc_eng, source = .Rebuilt},
					)
				} else {
					append(
						&report,
						Report{proc_name = hd.proc_name, eng_name = desc_eng, source = .Metadata},
					)
				}
				fmt.fprintf(out, "/// description = %s\n", desc_eng)
			}
			if len(hd.task_line) > 0 {
				fmt.fprintln(out, hd.task_line)
			}
			fmt.fprintln(out, hd.sign_line)
			fmt.fprintln(out, line)
			state = .Ouside
		}
	}
	return report[:]
}

// Convert an english description to snake case.
// This matches the logic in gen-exercise.sh.
to_snake_case :: proc(english: string) -> string {

	// Nested case descriptions are separated by " -> ", let fix this first.
	mod_english, _ := strings.replace_all(english, " -> ", "__")
	// Special case, avoids "A = B" translating to "A___B"
	mod_english, _ = strings.replace_all(mod_english, " = ", "_equals_")
	buf := strings.builder_make()
	prev: rune
	for char in mod_english {
		switch {
		case 'A' <= char && char <= 'Z':
			if '0' <= prev && prev <= '9' || 'a' <= prev && prev <= 'z' {
				// Camel Case, convert it to snake case
				strings.write_rune(&buf, '_')
			}
			strings.write_rune(&buf, char)
		case char == ' ' || char == '-' || char == '_':
			strings.write_rune(&buf, '_')
		case '0' <= char && char <= '9':
			strings.write_rune(&buf, char)
		case 'a' <= char && char <= 'z':
			strings.write_rune(&buf, char)
		case 'a' <= char && char <= 'z':
			strings.write_rune(&buf, char)
		case:
		// Ignore non alphanumeric characters
		}
		prev = char
	}
	snake_case := strings.to_lower(strings.to_string(buf))
	return snake_case
}

// Attempt to revert the conversion from English to snake case.
// Obviously, it can't know about characters that were lost in
// the original conversion but it does a pretty good job.
rebuild_english :: proc(snake: string, cap: bool) -> string {

	if len(snake) == 0 { return "" }
	if len(snake) == 1 { return strings.to_upper(snake) }

	snake_no_test := snake
	if strings.starts_with(snake_no_test, "test_") {
		snake_no_test, _ = strings.substring_from(snake_no_test, 5)
	}

	// Caution with nested test cases: each level is separated with
	// 2 underscores. When going back we separate the level (in english)
	// with " -> ".
	buf := strings.builder_make()
	first := true
	for snk_level in strings.split(snake_no_test, "__") {
		lc_eng_level, _ := strings.replace_all(snk_level, "_", " ")
		english_level := capitalize(lc_eng_level) if cap else lc_eng_level
		if first {
			first = false
		} else {
			strings.write_string(&buf, " -> ")
		}
		strings.write_string(&buf, english_level)
	}
	return strings.to_string(buf)
}

// Capitalize the first word of a sentence.
capitalize :: proc(s: string) -> string {

	if len(s) == 0 { return "" }
	if len(s) == 1 { return strings.to_upper(s) }
	first_letter, _ := strings.substring(s, 0, 1)
	other_letters, _ := strings.substring_from(s, 1)
	return strings.concatenate({strings.to_upper(first_letter), other_letters})

}

// Remove the given prefix from the string, if it exists.
rm_prefix :: proc(s: string, prefix: string) -> string {

	if strings.starts_with(s, prefix) {
		trimmed_str, _ := strings.substring_from(s, len(prefix))
		return trimmed_str
	}
	return s
}

// Add a prefix to a string (always).
add_prefix :: proc(s: string, prefix: string) -> string {

	return strings.concatenate([]string{prefix, s})
}

// Read the Exercise tests.toml file and extract the mapping between snake case and
// english description. The second parameter indicates if all the English descriptions
// start with a capital letter. If they do, we will use that information if we have
// to rebuild an English description from snake case.
read_toml_data :: proc(tests_toml_path: string) -> (Snake_English_Map, bool, Error) {

	TomlData :: struct {
		uuid:         string,
		desc:         string,
		not_include:  bool,
		reimplements: string,
	}

	// Read the tests meta data from the tests.toml file.
	// We are reading too much for now but let's keep it in case we need more
	// data later.
	tdata, tdata_ok := os.read_entire_file_from_filename(tests_toml_path)
	if !tdata_ok {
		return nil, false, fmt.aprintf("Unable to open file %s\n", tests_toml_path)
	}

	uuid_re, re_err := regex.create(`\[([a-f0-9]+-[a-f0-9]+-[a-f0-9]+-[a-f0-9]+-[a-f0-9]+)\]`)
	capture := regex.preallocate_capture()
	ensure(re_err == nil)
	tests: [dynamic]TomlData
	in_entry: bool
	entry := TomlData{}

	must_cap := true
	lineno := 0
	for line in strings.split(string(tdata), "\n") {
		lineno += 1
		if in_entry {
			switch {
			case len(line) == 0:
				in_entry = false
				append(&tests, entry)
				entry = TomlData{}
			case strings.starts_with(line, "description = "):
				desc, _ := strings.substring(line, 15, len(line) - 1)
				entry.desc = desc
				if 'a' <= desc[0] && desc[0] <= 'z' {
					must_cap = false
				}
			case strings.starts_with(line, "include = "):
				include_as_str, _ := strings.substring(line, 10, len(line))
				switch include_as_str {
				case "true":
					entry.not_include = false
				case "false":
					entry.not_include = true
				case:
					return nil, false, fmt.aprintf(
						"Invalid value for include '%s' on line %d",
						include_as_str,
						lineno,
					)
				}
			case strings.starts_with(line, "reimplements = "):
				uuid, _ := strings.substring(line, 16, len(line) - 1)
				entry.reimplements = uuid
			}
		} else {
			_, success := regex.match(uuid_re, line, &capture)
			if success {
				in_entry = true
				entry.uuid = capture.groups[1]
			}

		}
	}

	snk_to_eng: Snake_English_Map
	for test in tests {
		if !test.not_include {
			test_desc_eng := test.desc
			test_desc_snk := to_snake_case(test_desc_eng)
			snk_to_eng[test_desc_snk] = test_desc_eng
		}
	}

	return snk_to_eng, must_cap, nil
}

// Read the Exercise canonical data and extract the mapping between snake case and
// english description. The second parameter indicates if all the English descriptions
// start with a capital letter. If they do, we will use that information if we have
// to rebuild an English description from snake case.
read_canonical_data :: proc(cdata_path: string) -> (Snake_English_Map, bool, Error) {

	// Read the JSON data out of the canonical data file.
	cdata, cdata_ok := os.read_entire_file_from_filename(cdata_path)
	if !cdata_ok {
		return nil, false, fmt.aprintf("Unable to open canonical data file %s\n", cdata_path)
	}

	json_data, json_err := json.parse(cdata)
	if json_err != .None {
		return nil, false, fmt.aprintf(
			"Failed to parse the canonical data as json: %v\n",
			json_err,
		)
	}

	// Populate the Snake to English map.
	snk_to_eng: Snake_English_Map
	root_object := json_data.(json.Object)
	cases_array := root_object["cases"].(json.Array)
	must_cap := populate_test_from_json_data(cases_array, "", "", &snk_to_eng)

	return snk_to_eng, must_cap, nil
}

// Read the descriptions from the JSON blob extracted from the
// canonical data.
//
// Since the test cases can be nested, this function recurses
// until there are no more nested test cases.
populate_test_from_json_data :: proc(
	cases: json.Array,
	prefix_eng: string,
	prefix_snk: string,
	snk_to_eng: ^Snake_English_Map,
) -> bool {

	// If any of the descriptions start with a lowercase, then we will not mark the metadata
	// as "must be capitalize". We only test this for the first layer.
	must_cap := true
	for test in cases {
		test_object := test.(json.Object)
		test_desc_eng := test_object["description"].(string)
		if 'a' <= test_desc_eng[0] && test_desc_eng[0] <= 'z' {
			must_cap = false
		}
		test_desc_snk := to_snake_case(test_desc_eng)
		ext_desc_eng :=
			test_desc_eng if prefix_eng == "" else strings.join({prefix_eng, test_desc_eng}, " -> ")
		ext_desc_snk :=
			test_desc_snk if prefix_snk == "" else strings.join({prefix_snk, test_desc_snk}, "__")
		snk_to_eng[ext_desc_snk] = ext_desc_eng
		if test_object["cases"] != nil {
			sub_cases_array := test_object["cases"].(json.Array)
			// Ignore the return parameter, we are only interested in knowing if the first
			// level uses all capitalized words.
			populate_test_from_json_data(sub_cases_array, ext_desc_eng, ext_desc_snk, snk_to_eng)
		}
	}
	return must_cap
}
